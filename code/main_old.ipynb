{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Todos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## General\n",
    "\n",
    "- bale ta ballast trips apo ships tensor pisw sto ships df ❌\n",
    "- ananewne ka8w fora ta contracts_df kai ships_df me oti allagh ginetai stous contracts_tensor kai ships_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Allakse to state otan allazei h mera ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "afou looparw se ola ta available ships shmainei oti h mera allazei\n",
    "\n",
    "   #### - diamorfwse katallhla to ships log ❌\n",
    "   \n",
    "          * to ships log prepei na exei values >= 0 ❌\n",
    "          * apo mh mhdenika ships log values afairese 1 epeidh perase mia mera ❌\n",
    "          * an prokypsoun ships_log[ship] = 0 tote kane to `ship_availability` autou tou ship 1 ❌\n",
    "          * osa ships einai available (exoun ships_log[ship] == 0) bainoun se lista `available_ships` pou 8a thn allazeis ka8e mera. ❌\n",
    "           \n",
    "\n",
    "   #### -  kane generate 4 nea contracts ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pws ypologizw to `reward` apo to action  ✅\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "   #### - Value of contract ✅\n",
    "   #### - CII ✅\n",
    "   #### - Lateness ✅\n",
    "   #### - Ftiakse sugentrwtiko `calculate_reward(selected_ship_idx,selected_contract,selected_speed)` function ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pws na kanw swsta update to `state`  ✅\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "      \n",
    "   #### - contract tensor ✅\n",
    "   #### - ship tensor ✅\n",
    "   #### - contract mask ✅\n",
    "   #### - ship mask ✅\n",
    "   #### - ship_log ✅\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train \n",
    "\n",
    "ti einai ta `advantages`, `returns` kai giati xrhsimopoioyntai:\n",
    "        \n",
    "- ❌ sthn baseline_net.update(observations, returns) gia to update to baselineNet\n",
    "- ❌ sthn PolicyGradient.update_policy(observations, actions, advantages)gia to update ths policygradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreloading modules that i change in vscode\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_dict = {\n",
    "    \"fleet_path\": \"data/fleet_small.csv\",\n",
    "    \"ports_path\": \"data/ports_10.csv\",\n",
    "    \"dm_path\": \"data/distance_matrix.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "ports_df = pd.read_csv(data_dict[\"ports_path\"])\n",
    "fleet_df = pd.read_csv(data_dict[\"fleet_path\"])\n",
    "distance_matrix = pd.read_csv(data_dict[\"dm_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.env import CarbonEnv\n",
    "from models.models import BaselineNet, PolicyNet, CarbonModel\n",
    "from training.training_functions import PolicyGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "envo = CarbonEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolicyGradient(envo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ksekina to year: 0\n",
      "Xronia: 0 kai mera: 0\n",
      "Ta available ships einai [1, 2, 3, 4]\n",
      "Xronia: 0 kai mera: 1\n",
      "Ta available ships einai [1, 4]\n",
      "Den phra contract gia to available ship 4 \n",
      "Xronia: 0 kai mera: 2\n",
      "Ta available ships einai [4]\n",
      "Xronia: 0, sunolo apo steps: 7 \n",
      "To synoliko reward gia to year 0 htan 11.565890789031982\n",
      "The prediction is[433.45096]\n",
      "The loss is 178614.734375\n",
      "The prediction is[-208853.47]\n",
      "The loss is 43619176448.0\n",
      "The prediction is[93.12628]\n",
      "The loss is 12413.7548828125\n",
      "The prediction is[2876.6843]\n",
      "The loss is 8070941.0\n",
      "The prediction is[-8552.2]\n",
      "The loss is 73659176.0\n",
      "The prediction is[1272.8422]\n",
      "The loss is 1586127.75\n",
      "The prediction is[3194.955]\n",
      "The loss is 10114835.0\n",
      "Average reward for batch 0: 12.16\n",
      "Ksekina to year: 1\n",
      "Xronia: 1 kai mera: 0\n",
      "Ta available ships einai [1, 2, 3, 4]\n",
      "Xronia: 1 kai mera: 1\n",
      "Ta available ships einai [4]\n",
      "Xronia: 1 kai mera: 2\n",
      "Ta available ships einai [1, 3]\n",
      "Den phra contract gia to available ship 3 \n",
      "Xronia: 1, sunolo apo steps: 7 \n",
      "To synoliko reward gia to year 1 htan -45.455496311187744\n",
      "The prediction is[2284.8125]\n",
      "The loss is 5430197.0\n",
      "The prediction is[1443.9911]\n",
      "The loss is 2210736.0\n",
      "The prediction is[155.79568]\n",
      "The loss is 15907.9462890625\n",
      "The prediction is[-1324.074]\n",
      "The loss is 1800494.875\n",
      "The prediction is[-587.13654]\n",
      "The loss is 346975.71875\n",
      "The prediction is[977.6105]\n",
      "The loss is 964418.125\n",
      "The prediction is[443.4588]\n",
      "The loss is 197543.625\n",
      "Average reward for batch 1: -6.35\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 13:06:40.633198: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/models/baseline/assets\n",
      "INFO:tensorflow:Assets written to: ../results/models/policynet/assets\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run this cell when needing to reload the classes CarbonEnv, BaselineNet, PolicyNet\n",
    "\n",
    "del sys.modules['models.models']\n",
    "del sys.modules['env.env']\n",
    "del sys.modules['training.training_functions']\n",
    "del sys.modules['utils.utils']\n",
    "\n",
    "from env.env import CarbonEnv\n",
    "from models.models import BaselineNet, PolicyNet, CarbonModel\n",
    "from training.training_functions import PolicyGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_net = BaselineNet(128,1)\n",
    "policy_net = PolicyNet(128,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envo = CarbonEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolicyGradient(envo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_array = year_data['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_array = year_data['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_array = year_data['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(rewards_array):\n",
    "    T = len(rewards_array)\n",
    "    discounts = np.logspace(0,T,num=T, base=0.70, endpoint=False)\n",
    "    returns = np.array([np.sum(discounts[:T-t] * rewards_array[t:]) for t in range(T)])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = get_returns(rewards_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advantage(returns, states):\n",
    "    value_array = np.array([])\n",
    "    for state in states:\n",
    "        value = baseline_net.forward(state).numpy()\n",
    "        value_array = np.append(value_array,value)\n",
    "    advantages = returns - value_array\n",
    "    advantages = (advantages - np.mean(advantages)) / np.sqrt(np.sum(advantages ** 2))\n",
    "    return advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages = get_advantage(returns,states_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_state = states_array[0]\n",
    "one_return = returns[0]\n",
    "one_advantage = advantages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_action = actions_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_state, one_return, one_advantage,one_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_net.update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_net.update(one_state,one_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(one_state, one_action, one_advantage):\n",
    "    #one_state is already a tensor\n",
    "    one_action = tf.convert_to_tensor(one_action)\n",
    "    one_advantage = tf.convert_to_tensor(one_advantage)\n",
    "    with tf.GradientTape() as tape:\n",
    "        log_prob = policy_net.action_distribution(one_state)[1].log_prob(one_action)\n",
    "        loss = -tf.math.reduce_mean(log_prob * tf.cast(one_advantage, tf.float32))\n",
    "    grads = tape.gradient(loss, policy_net.policy_model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, policy_net.policy_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"f\":29,'d':43}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(a):\n",
    "    print(f\"to numero einai {i}\")\n",
    "    print(f\"to key einai {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tensorflow Tip\n",
    "\n",
    "Assign values to a tensor at specific indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_array = np.array([2, 4, 7, 11, 3, 8, 9, 19, 11, 7])\n",
    "inplace_array = np.array([10, 20])\n",
    "indices_array = np.array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n",
    "\n",
    "# [[2], [6]] \n",
    "indices = tf.cast(tf.where(tf.equal(indices_array,1)),tf.int32)\n",
    "print(indices)\n",
    "\n",
    "# [0, 0, 10, 0, 0, 0, 20, 0, 0, 0]\n",
    "scatter = tf.scatter_nd(indices, inplace_array, shape=tf.shape(input_array))\n",
    "print(scatter)\n",
    "\n",
    "# [1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "inverse_mask = tf.cast(tf.math.logical_not(indices_array), tf.int32)\n",
    "print(inverse_mask)\n",
    "\n",
    "# [2, 4, 0, 11, 3, 8, 0, 19, 11, 7]\n",
    "input_array_zero_out = tf.multiply(inverse_mask, input_array)\n",
    "print(input_array_zero_out)\n",
    "\n",
    "# [2, 4, 10, 11, 3, 8, 20, 19, 11, 7]\n",
    "output = tf.add(input_array_zero_out, tf.cast(scatter, tf.int32))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [[2], [6]] \n",
    "indices = tf.cast(tf.where(tf.equal(indices_array,1)),tf.int32)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [0, 0, 10, 0, 0, 0, 20, 0, 0, 0]\n",
    "scatter = tf.scatter_nd(indices, inplace_array, shape=tf.shape(input_array))\n",
    "print(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "inverse_mask = tf.cast(tf.math.logical_not(indices_array), tf.int32)\n",
    "print(inverse_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [2, 4, 0, 11, 3, 8, 0, 19, 11, 7]\n",
    "input_array_zero_out = tf.multiply(inverse_mask, input_array)\n",
    "print(input_array_zero_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [2, 4, 10, 11, 3, 8, 20, 19, 11, 7]\n",
    "output = tf.add(input_array_zero_out, tf.cast(scatter, tf.int32))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encoder mlp\n",
    "\n",
    "# see https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "# see https://www.tensorflow.org/tutorials/generative/autoencoder\n",
    "# Create an Integer Categorical Feature for contract_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0ef8fd9461b8a7174e04371100f893194f575b4895c82467862fe3595d34e0f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('rl': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd0aab302a361633d0f4220ac63331fe65e9bd63faf3f5b6c8e967bb743dd0eb01b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "114px",
    "width": "231px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
